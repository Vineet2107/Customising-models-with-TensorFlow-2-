{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Coding Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vineet2107/Customising-models-with-TensorFlow-2-/blob/main/Coding_Tutorial_Week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqSyHY-r3x3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2c70e19-1df1-41d6-e720-c5ab420b57ce"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOWP0ONw3x3R"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwRqzR_X3x3S"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4BpEP6k3x3S"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-okAiF-3x3T"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMpz98a73x3T"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_EWeNYM3x3U"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "      super(MyModel, self).__init__()\n",
        "      self.dense_1 = Dense(64, activation='relu')\n",
        "      self.dense_2 = Dense(10)\n",
        "      self.dense_3 = Dense(5)\n",
        "      self.softmax = Softmax()\n",
        "\n",
        "  def call(self, inputs):\n",
        "      x = self.dense_1(inputs)\n",
        "      y1 = self.dense_2(inputs)\n",
        "      y2 = self.dense_3(y1)\n",
        "      concat = concatenate([x, y2])\n",
        "      return self.softmax(concat)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6R9qyNj3x3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea0f259-812c-4d56-bebe-4cc51bd323f2"
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1,10]))\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  704       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  55        \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            multiple                  0         \n",
            "=================================================================\n",
            "Total params: 869\n",
            "Trainable params: 869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcb9zhT03x3U"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmWO4cTN3x3V"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heWUfa7X3x3V"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdJW_qJ-3x3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a396763-842e-421b-ebf8-748685f98014"
      },
      "source": [
        "# Create a custom layer\n",
        "\n",
        "class MyLayer(Layer):\n",
        "    \n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.W = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "                                 initializer='zeros')\n",
        "        \n",
        "        def call(self, input):\n",
        "            return tf.matmul(inputs, self.w)+self.b\n",
        "dense_layer = MyLayer(3,5)\n",
        "x = tf.ones((1,5))\n",
        "print(dense_layer(x))\n",
        "print(dense_layer.weights)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[1. 1. 1. 1. 1.]], shape=(1, 5), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[-0.01898911,  0.072402  ,  0.01793057],\n",
            "       [-0.06924512,  0.03352962,  0.03701708],\n",
            "       [-0.02909693, -0.00956737, -0.100604  ],\n",
            "       [-0.07509243,  0.05560825, -0.04364246],\n",
            "       [ 0.06294969,  0.00042775, -0.08723205]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk0WW1_NpdT-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT_N6Em-3x3V"
      },
      "source": [
        "# Specify trainable weights\n",
        "class MyLayer(Layer):\n",
        "    \n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.W = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=False)\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "                                 initializer='zeros')\n",
        "        \n",
        "        def call(self, input):\n",
        "            return tf.matmul(inputs, self.w)+self.b\n",
        "dense_layer = MyLayer(3,5)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPI5K_Cw3x3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54776b80-02cd-45af-99e7-873846b3a420"
      },
      "source": [
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable weights: 1\n",
            "non-trainable weights: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeVwsv9c3x3W"
      },
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "\n",
        "class MyLayerMean(Layer):\n",
        "    \n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayerMean, self).__init__()\n",
        "        self.W = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "                                 initializer='zeros')\n",
        "        self.sum_activation = tf.Variable(initial_value=tf.zeros((units,)),\n",
        "                                          trainable=False)\n",
        "        self.number_call = tf.Variable(initial_value=0,\n",
        "                                       trainable=False)\n",
        "        \n",
        "    def call(self, input):\n",
        "        activation = tf.matmul(input, self.W)+self.b\n",
        "        self.sum_activation.assign_add(tf.reduce_sum(activation, axis=0))\n",
        "        self.number_call.assign_add(input.shape[0])\n",
        "        return activation, self.sum_activation / tf.cast(self.number_call, tf.float32)    \n",
        "dense_layer = MyLayerMean(3,5)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDYWMehE3x3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1eb3f3-ba98-4652-88e5-853fec33415c"
      },
      "source": [
        "# Test the layer\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.08605132  0.25168934  0.0192831 ]\n",
            "[-0.08605132  0.25168934  0.0192831 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItgLy94W3x3X"
      },
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKDT-uqe3x3X"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLLaJmnn3x3X"
      },
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Softmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return self.softmax(x)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNyehbbv3x3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47f1549-8308-423a-8412-d12b3992e86a"
      },
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[6.8831737e-06 6.8831737e-06 6.8831737e-06 ... 6.8831737e-06\n",
            "  6.8831737e-06 6.8831737e-06]], shape=(1, 10000), dtype=float32)\n",
            "Model: \"my_model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_layer_2 (MyLayer)         multiple                  640064    \n",
            "_________________________________________________________________\n",
            "my_dropout (MyDropout)       multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_3 (MyLayer)         multiple                  4160      \n",
            "_________________________________________________________________\n",
            "my_dropout_1 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_4 (MyLayer)         multiple                  2990      \n",
            "_________________________________________________________________\n",
            "softmax_1 (Softmax)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 174\n",
            "Non-trainable params: 647,040\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8dcMKgs3x3Y"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUCmB7Tf3x3Y"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdx-S_jZ3x3Y"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gkIZHDb3x3Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "8b474155-cff6-4932-9300-a058e30061ea"
      },
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "m=1\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f023c25a950>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKHRGf-U3x3Z"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHVR4Csz3x3Z"
      },
      "source": [
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJgwhCKh3x3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc8475e-eeac-4039-fd62-11b093a1075e"
      },
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n",
        "class LinearLayer(Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LinearLayer, self).__init__()\n",
        "        self.m = self.add_weight(shape=(1,),\n",
        "                                initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(1,),\n",
        "                                initializer='zeros')\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return self.m+self.b\n",
        "linear_regression = LinearLayer()\n",
        "\n",
        "print(linear_regression(x_train))\n",
        "print(linear_regression.weights)\n",
        "    "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0.04819635], shape=(1,), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.04819635], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAOlu03_3x3a"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fRlSYEI3x3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ccdc00-b717-4239-c8f8-2a70c8bba7be"
      },
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
        "\n",
        "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting loss 6.172035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwuxKqMg3x3a"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD8tzk4J3x3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5885854f-bd1d-4396-ae8e-f110d67363d8"
      },
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n",
        "learning_rate = 0.05\n",
        "steps = 25\n",
        "\n",
        "for i in range(steps):\n",
        "   with tf.GradientTape() as tape:\n",
        "       predictions = linear_regression(x_train)\n",
        "       loss = SquaredError(predictions, y_train)\n",
        "   gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
        "\n",
        "   linear_regression.m.assign_sub(learning_rate*gradients[0])\n",
        "   linear_regression.m.assign_sub(learning_rate*gradients[0])\n",
        "\n",
        "   print('Step %d, Loss %f' % (i, loss.numpy()))\n",
        "   "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 6.172035\n",
            "Step 1, Loss 3.977543\n",
            "Step 2, Loss 2.573068\n",
            "Step 3, Loss 1.674204\n",
            "Step 4, Loss 1.098932\n",
            "Step 5, Loss 0.730757\n",
            "Step 6, Loss 0.495125\n",
            "Step 7, Loss 0.344321\n",
            "Step 8, Loss 0.247806\n",
            "Step 9, Loss 0.186037\n",
            "Step 10, Loss 0.146504\n",
            "Step 11, Loss 0.121203\n",
            "Step 12, Loss 0.105011\n",
            "Step 13, Loss 0.094648\n",
            "Step 14, Loss 0.088015\n",
            "Step 15, Loss 0.083770\n",
            "Step 16, Loss 0.081054\n",
            "Step 17, Loss 0.079315\n",
            "Step 18, Loss 0.078202\n",
            "Step 19, Loss 0.077490\n",
            "Step 20, Loss 0.077034\n",
            "Step 21, Loss 0.076743\n",
            "Step 22, Loss 0.076556\n",
            "Step 23, Loss 0.076437\n",
            "Step 24, Loss 0.076360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvPB8Uo23x3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "d5647934-9ff2-4395-963a-1f9f874f5a21"
      },
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
        "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m:1,  trained m:[2.5078382]\n",
            "b:2,  trained b:[0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f023bb4b890>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLcikix23x3b"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXiZU7Ik3x3b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVcLnayd3x3b"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siJ_D_5C3x3b"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OL1_yHm3x3c"
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n",
        "class MyLayer(Layer):\n",
        "    \n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.W = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "                                 initializer='zeros')\n",
        "        \n",
        "    def call(self, input):\n",
        "            return tf.matmul(inputs, self.w)+self.b\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = Mylayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Softmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return self.softmax(x)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA014aPm3x3c"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNAAvgP83x3c",
        "outputId": "d608c97a-e341-461a-9e01-77877c5b2516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:143: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:144: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pnG_drt3x3c",
        "outputId": "e072681f-1be4-453a-a346-fefd5a87de4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: earn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFixmzVm3x3d"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdGGvSe13x3d",
        "outputId": "9b88d184-1222-431e-dc30-52522cb5d5d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnSGl-Ix3x3e"
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wabMPnMd3x3e"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGjgGldh3x3e",
        "outputId": "9b4f85af-c20e-4c9a-82c7-affe21e482fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train: (8982, 10000)\n",
            "Shape of x_test: (2246, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78GCAMYS3x3e"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnHcx8Hl3x3f"
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BUs1wGn3x3f"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjOD06R43x3f"
      },
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIgv7MnC3x3f",
        "outputId": "9542179e-cf7b-4ba3-8d08-ac879cd81375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "    \n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Duration :0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aha1zWg23x3f"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PtPrWoN3x3g"
      },
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7J4T9La3x3g"
      },
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pecSD1z3x3g",
        "outputId": "c24a8c12-d75e-4993-8b0d-98014ad793a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value = loss(model, x, y, weight_decay)    \n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)  \n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-52baa918b9ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Optimize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Compute current loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mepoch_loss_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'weight_decay' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EHmk4ob3x3g"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCCKTdtI3x3h",
        "outputId": "ae933a3b-fa47-4149-d0a9-9545cd8546bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-c95e54902442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loss_results' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW4gGSQN3x3h"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HWD-MFk3x3h",
        "outputId": "e80e1fb7-aeec-4439-eab6-595536ace8e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: veg-oil\n",
            "     Label: earn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfylvUvb3x3h"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6fp-jaK3x3h"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEZbQuzP3x3i"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plsMM8H43x3i"
      },
      "source": [
        "# Initialize a new model\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9z30FnK3x3i"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z2YxeId3x3i"
      },
      "source": [
        "# Use the @tf.function decorator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7UDfJzS3x3i"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYxLJqV13x3j"
      },
      "source": [
        "# Re-run the training loop\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53pMozg83x3j"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11W-HmjJ3x3j"
      },
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}