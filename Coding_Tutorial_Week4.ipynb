{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Coding Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vineet2107/Customising-models-with-TensorFlow-2-/blob/main/Coding_Tutorial_Week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqSyHY-r3x3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d440a02-1347-46ab-c702-4172ae5e26e3"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOWP0ONw3x3R"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwRqzR_X3x3S"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4BpEP6k3x3S"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-okAiF-3x3T"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMpz98a73x3T"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_EWeNYM3x3U"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "      super(MyModel, self).__init__()\n",
        "      self.dense_1 = Dense(64, activation='relu')\n",
        "      self.dense_2 = Dense(10)\n",
        "      self.dense_3 = Dense(5)\n",
        "      self.softmax = Softmax()\n",
        "\n",
        "  def call(self, inputs):\n",
        "      x = self.dense_1(inputs)\n",
        "      y1 = self.dense_2(inputs)\n",
        "      y2 = self.dense_3(y1)\n",
        "      concat = concatenate([x, y2])\n",
        "      return self.softmax(concat)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6R9qyNj3x3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84768358-c982-4be5-9212-4a8d56a54b46"
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1,10]))\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  704       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  55        \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            multiple                  0         \n",
            "=================================================================\n",
            "Total params: 869\n",
            "Trainable params: 869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcb9zhT03x3U"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmWO4cTN3x3V"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heWUfa7X3x3V"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdJW_qJ-3x3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab9bad3-a60a-47df-914b-455edf45b432"
      },
      "source": [
        "# Create a custom layer\n",
        "\n",
        "class MyLayer(Layer):\n",
        "    \n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.W = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "                                 initializer='zeros')\n",
        "        \n",
        "        def call(self, input):\n",
        "            return tf.matmul(inputs, self.w)+self.b\n",
        "dense_layer = MyLayer(3,5)\n",
        "x = tf.ones((1,5))\n",
        "print(dense_layer(x))\n",
        "print(dense_layer.weights)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[1. 1. 1. 1. 1.]], shape=(1, 5), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[-0.0037608 , -0.05139053,  0.03107335],\n",
            "       [-0.0553619 ,  0.13144767,  0.00791469],\n",
            "       [-0.08951922, -0.05857417, -0.02623582],\n",
            "       [-0.03218774, -0.03483859,  0.04152387],\n",
            "       [-0.09636521, -0.00619469,  0.02730225]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk0WW1_NpdT-"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT_N6Em-3x3V"
      },
      "source": [
        "# Specify trainable weights\n",
        "class MyLayer(Layer):\n",
        "    \n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.W = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=False)\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "                                 initializer='zeros')\n",
        "        \n",
        "        def call(self, input):\n",
        "            return tf.matmul(inputs, self.w)+self.b\n",
        "dense_layer = MyLayer(3,5)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPI5K_Cw3x3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6588e060-0575-4516-e8eb-e38d1d2b2df0"
      },
      "source": [
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable weights: 1\n",
            "non-trainable weights: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeVwsv9c3x3W"
      },
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "\n",
        "class MyLayerMean(Layer):\n",
        "    \n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayerMean, self).__init__()\n",
        "        self.W = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "                                 initializer='zeros')\n",
        "        self.sum_activation = tf.Variable(initial_value=tf.zeros((units,)),\n",
        "                                          trainable=False)\n",
        "        self.number_call = tf.Variable(initial_value=0,\n",
        "                                       trainable=False)\n",
        "        \n",
        "    def call(self, input):\n",
        "        activation = tf.matmul(inputs, self.w)+self.b\n",
        "        self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
        "        self.number_call.assign_add(inputs.shape[0])\n",
        "        return activation, self.sum_activation / tf.cast(self.number_call, tf.float32)    \n",
        "dense_layer = MyLayerMean(3,5)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDYWMehE3x3W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "929b92b2-8c14-456f-a9f3-143286956676"
      },
      "source": [
        "# Test the layer\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-43b27dec17ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test the layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_means\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-a86c3ab361a0>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_activation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItgLy94W3x3X"
      },
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKDT-uqe3x3X"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLLaJmnn3x3X"
      },
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = Mylayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Softmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return self.softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNyehbbv3x3Y"
      },
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8dcMKgs3x3Y"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUCmB7Tf3x3Y"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdx-S_jZ3x3Y"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gkIZHDb3x3Z",
        "outputId": "3577ee9d-e3b4-4ddd-e115-0012aac7c0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "m=1\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f067bdd28d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKHRGf-U3x3Z"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHVR4Csz3x3Z"
      },
      "source": [
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJgwhCKh3x3Z",
        "outputId": "6ef085b9-00d4-488e-a514-437345dce3ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n",
        "class LinearLayer(Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LinearLayer, self).__init__()\n",
        "        self.m = self.add_weight(shape=(1,),\n",
        "                                initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(1,),\n",
        "                                initializer='zeros')\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return self.m+self.b\n",
        "linear_regression = LinearLayer()\n",
        "\n",
        "print(linear_regression(x_train))\n",
        "print(linear_regression.weights)\n",
        "    "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([-0.00949256], shape=(1,), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-0.00949256], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAOlu03_3x3a"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fRlSYEI3x3a",
        "outputId": "2986753f-7ebc-4ee7-ff70-6629a97e429b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
        "\n",
        "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting loss 5.989108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwuxKqMg3x3a"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD8tzk4J3x3a",
        "outputId": "08f35416-8834-454d-c4d2-ccb18859da9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n",
        "learning_rate = 0.05\n",
        "steps = 25\n",
        "\n",
        "for i in range(steps):\n",
        "   with tf.GradientTape() as tape:\n",
        "       predictions = linear_regression(x_train)\n",
        "       loss = SquaredError(predictions, y_train)\n",
        "   gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
        "\n",
        "   linear_regression.m.assign_sub(learning_rate*gradients[0])\n",
        "   linear_regression.m.assign_sub(learning_rate*gradients[0])\n",
        "\n",
        "   print('Step %d, Loss %f' % (i, loss.numpy()))\n",
        "   "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 5.989108\n",
            "Step 1, Loss 3.853622\n",
            "Step 2, Loss 2.486911\n",
            "Step 3, Loss 1.612217\n",
            "Step 4, Loss 1.052412\n",
            "Step 5, Loss 0.694137\n",
            "Step 6, Loss 0.464841\n",
            "Step 7, Loss 0.318092\n",
            "Step 8, Loss 0.224172\n",
            "Step 9, Loss 0.164063\n",
            "Step 10, Loss 0.125594\n",
            "Step 11, Loss 0.100974\n",
            "Step 12, Loss 0.085217\n",
            "Step 13, Loss 0.075132\n",
            "Step 14, Loss 0.068678\n",
            "Step 15, Loss 0.064547\n",
            "Step 16, Loss 0.061904\n",
            "Step 17, Loss 0.060212\n",
            "Step 18, Loss 0.059129\n",
            "Step 19, Loss 0.058436\n",
            "Step 20, Loss 0.057992\n",
            "Step 21, Loss 0.057708\n",
            "Step 22, Loss 0.057527\n",
            "Step 23, Loss 0.057411\n",
            "Step 24, Loss 0.057336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvPB8Uo23x3a",
        "outputId": "934fa31f-0b2f-467d-b4fa-776dac518d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
        "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m:1,  trained m:[2.4168563]\n",
            "b:2,  trained b:[0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f06772ebf50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLcikix23x3b"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXiZU7Ik3x3b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVcLnayd3x3b"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siJ_D_5C3x3b"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OL1_yHm3x3c"
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA014aPm3x3c"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNAAvgP83x3c"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pnG_drt3x3c"
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFixmzVm3x3d"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdGGvSe13x3d"
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnSGl-Ix3x3e"
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wabMPnMd3x3e"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGjgGldh3x3e"
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78GCAMYS3x3e"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnHcx8Hl3x3f"
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BUs1wGn3x3f"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjOD06R43x3f"
      },
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIgv7MnC3x3f"
      },
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "    \n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aha1zWg23x3f"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PtPrWoN3x3g"
      },
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7J4T9La3x3g"
      },
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pecSD1z3x3g"
      },
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value = loss(model, x, y, weight_decay)    \n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)  \n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EHmk4ob3x3g"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCCKTdtI3x3h"
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW4gGSQN3x3h"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HWD-MFk3x3h"
      },
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfylvUvb3x3h"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6fp-jaK3x3h"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEZbQuzP3x3i"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plsMM8H43x3i"
      },
      "source": [
        "# Initialize a new model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9z30FnK3x3i"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z2YxeId3x3i"
      },
      "source": [
        "# Use the @tf.function decorator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7UDfJzS3x3i"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYxLJqV13x3j"
      },
      "source": [
        "# Re-run the training loop\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53pMozg83x3j"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11W-HmjJ3x3j"
      },
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}