{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Coding Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vineet2107/Customising-models-with-TensorFlow-2-/blob/main/Coding_Tutorial_Week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqSyHY-r3x3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0ca856-92e0-41de-b520-eab5222cfe61"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOWP0ONw3x3R"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwRqzR_X3x3S"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4BpEP6k3x3S"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-okAiF-3x3T"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMpz98a73x3T"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_EWeNYM3x3U"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "      super(MyModel, self).__init__()\n",
        "      self.dense_1 = Dense(64, activation='relu')\n",
        "      self.dense_2 = Dense(10)\n",
        "      self.dense_3 = Dense(5)\n",
        "      self.softmax = Softmax()\n",
        "\n",
        "  def call(self, inputs):\n",
        "      x = self.dense_1(inputs)\n",
        "      y1 = self.dense_2(inputs)\n",
        "      y2 = self.dense_3(y1)\n",
        "      concat = concatenate([x, y2])\n",
        "      return self.softmax(concat)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6R9qyNj3x3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7adcd8b-85c0-4d9f-850d-1b468c641764"
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1,10]))\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  704       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  55        \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            multiple                  0         \n",
            "=================================================================\n",
            "Total params: 869\n",
            "Trainable params: 869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcb9zhT03x3U"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmWO4cTN3x3V"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heWUfa7X3x3V"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdJW_qJ-3x3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04d8fdc-2af0-4839-8c79-a1ff95eab007"
      },
      "source": [
        "# Create a custom layer\n",
        "\n",
        "class MyLayer(Layer):\n",
        "    \n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.W = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "                                 initializer='zeros')\n",
        "        \n",
        "        def call(self, input):\n",
        "            return tf.matmul(inputs, self.w)+self.b\n",
        "dense_layer = MyLayer(3,5)\n",
        "x = tf.ones((1,5))\n",
        "print(dense_layer(x))\n",
        "print(dense_layer.weights)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[1. 1. 1. 1. 1.]], shape=(1, 5), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[ 0.01954057,  0.02380767, -0.02286018],\n",
            "       [-0.01104596,  0.04056986,  0.07839682],\n",
            "       [-0.12555873, -0.00577318,  0.00978197],\n",
            "       [ 0.03390256, -0.00114198,  0.02676562],\n",
            "       [ 0.00882842,  0.04701686,  0.03203111]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk0WW1_NpdT-"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT_N6Em-3x3V"
      },
      "source": [
        "# Specify trainable weights\n",
        "class MyLayer(Layer):\n",
        "    \n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.W = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=False)\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "                                 initializer='zeros')\n",
        "        \n",
        "        def call(self, input):\n",
        "            return tf.matmul(inputs, self.w)+self.b\n",
        "dense_layer = MyLayer(3,5)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPI5K_Cw3x3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f1376a-81a8-462e-84ab-82bd22cfe2b3"
      },
      "source": [
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable weights: 1\n",
            "non-trainable weights: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeVwsv9c3x3W"
      },
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "\n",
        "class MyLayerMean(Layer):\n",
        "    \n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayerMean, self).__init__()\n",
        "        self.W = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "                                 initializer='zeros')\n",
        "        self.sum_activation = tf.Variable(initial_value=tf.zeros((units,)),\n",
        "                                          trainable=False)\n",
        "        self.number_call = tf.Variable(initial_value=0,\n",
        "                                       trainable=False)\n",
        "        \n",
        "    def call(self, input):\n",
        "        activation = tf.matmul(inputs, self.w)+self.b\n",
        "        self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
        "        self.number_call.assign_add(inputs.shape[0])\n",
        "        return activation, self.sum_activation / tf.cast(self.number_call, tf.float32)    \n",
        "dense_layer = MyLayerMean(3,5)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDYWMehE3x3W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "c8ea0ae1-4546-4eed-ad0d-2eaf496c91dd"
      },
      "source": [
        "# Test the layer\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-43b27dec17ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test the layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_means\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-a86c3ab361a0>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_activation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItgLy94W3x3X"
      },
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKDT-uqe3x3X"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLLaJmnn3x3X"
      },
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = Mylayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Softmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return self.softmax(x)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNyehbbv3x3Y",
        "outputId": "1af8d888-4ea7-42d0-ecd9-29dbff637ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3d77559566ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantiate a model object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-4a2824ce1aef>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units_1, input_dim_1, units_2, units_3)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Define layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMylayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Mylayer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8dcMKgs3x3Y"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUCmB7Tf3x3Y"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdx-S_jZ3x3Y"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gkIZHDb3x3Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1d4656c6-133b-44a0-d690-0e4d67de76a2"
      },
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "m=1\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f921df35110>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKHRGf-U3x3Z"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHVR4Csz3x3Z"
      },
      "source": [
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJgwhCKh3x3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94087d15-9882-4204-c31d-c309d3545aa6"
      },
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n",
        "class LinearLayer(Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LinearLayer, self).__init__()\n",
        "        self.m = self.add_weight(shape=(1,),\n",
        "                                initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(1,),\n",
        "                                initializer='zeros')\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return self.m+self.b\n",
        "linear_regression = LinearLayer()\n",
        "\n",
        "print(linear_regression(x_train))\n",
        "print(linear_regression.weights)\n",
        "    "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([-0.09899402], shape=(1,), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-0.09899402], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAOlu03_3x3a"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fRlSYEI3x3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aaf1474-17bc-44b8-946b-a103539e2a1e"
      },
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
        "\n",
        "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting loss 6.889395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwuxKqMg3x3a"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD8tzk4J3x3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e4ed04-9410-4b96-e904-c7d269399cc2"
      },
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n",
        "learning_rate = 0.05\n",
        "steps = 25\n",
        "\n",
        "for i in range(steps):\n",
        "   with tf.GradientTape() as tape:\n",
        "       predictions = linear_regression(x_train)\n",
        "       loss = SquaredError(predictions, y_train)\n",
        "   gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
        "\n",
        "   linear_regression.m.assign_sub(learning_rate*gradients[0])\n",
        "   linear_regression.m.assign_sub(learning_rate*gradients[0])\n",
        "\n",
        "   print('Step %d, Loss %f' % (i, loss.numpy()))\n",
        "   "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 6.889395\n",
            "Step 1, Loss 4.440683\n",
            "Step 2, Loss 2.873509\n",
            "Step 3, Loss 1.870516\n",
            "Step 4, Loss 1.228601\n",
            "Step 5, Loss 0.817776\n",
            "Step 6, Loss 0.554848\n",
            "Step 7, Loss 0.386573\n",
            "Step 8, Loss 0.278878\n",
            "Step 9, Loss 0.209953\n",
            "Step 10, Loss 0.165841\n",
            "Step 11, Loss 0.137609\n",
            "Step 12, Loss 0.119541\n",
            "Step 13, Loss 0.107977\n",
            "Step 14, Loss 0.100576\n",
            "Step 15, Loss 0.095840\n",
            "Step 16, Loss 0.092808\n",
            "Step 17, Loss 0.090868\n",
            "Step 18, Loss 0.089627\n",
            "Step 19, Loss 0.088832\n",
            "Step 20, Loss 0.088323\n",
            "Step 21, Loss 0.087998\n",
            "Step 22, Loss 0.087790\n",
            "Step 23, Loss 0.087656\n",
            "Step 24, Loss 0.087571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvPB8Uo23x3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "346a4db1-038a-475d-b25c-5a8d8aedd5d9"
      },
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
        "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m:1,  trained m:[2.4992127]\n",
            "b:2,  trained b:[0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f921df18c90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLcikix23x3b"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXiZU7Ik3x3b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVcLnayd3x3b"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siJ_D_5C3x3b"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OL1_yHm3x3c"
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n",
        "class MyLayer(Layer):\n",
        "    \n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.W = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "                                 initializer='zeros')\n",
        "        \n",
        "    def call(self, input):\n",
        "            return tf.matmul(inputs, self.w)+self.b\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = Mylayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Softmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return self.softmax(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA014aPm3x3c"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNAAvgP83x3c"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pnG_drt3x3c"
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFixmzVm3x3d"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdGGvSe13x3d"
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnSGl-Ix3x3e"
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wabMPnMd3x3e"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGjgGldh3x3e"
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78GCAMYS3x3e"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnHcx8Hl3x3f"
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BUs1wGn3x3f"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjOD06R43x3f"
      },
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIgv7MnC3x3f"
      },
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "    \n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aha1zWg23x3f"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PtPrWoN3x3g"
      },
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7J4T9La3x3g"
      },
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pecSD1z3x3g"
      },
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value = loss(model, x, y, weight_decay)    \n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)  \n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EHmk4ob3x3g"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCCKTdtI3x3h"
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW4gGSQN3x3h"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HWD-MFk3x3h"
      },
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfylvUvb3x3h"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6fp-jaK3x3h"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEZbQuzP3x3i"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plsMM8H43x3i"
      },
      "source": [
        "# Initialize a new model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9z30FnK3x3i"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z2YxeId3x3i"
      },
      "source": [
        "# Use the @tf.function decorator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7UDfJzS3x3i"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYxLJqV13x3j"
      },
      "source": [
        "# Re-run the training loop\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53pMozg83x3j"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11W-HmjJ3x3j"
      },
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}